{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08372c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droplet and Vacuole Motion Analysis Notebook\n",
    "#Get all the packages needed\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import TiffFile\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from scipy.ndimage import center_of_mass\n",
    "from skimage.draw import polygon\n",
    "\n",
    "from ipywidgets import interact, IntSlider\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from matplotlib.path import Path\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "from skimage.transform import resize\n",
    "import matplotlib.cm as cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760d2d8",
   "metadata": {},
   "source": [
    "Read all xml files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read all XML files in a directory and its subdirectories\n",
    "def read_all_xml_files(base_folder):\n",
    "    xml_files = []\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_files.append(os.path.join(root, file))\n",
    "    return xml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be558f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List XML files from the current working directory\n",
    "base_folder = os.getcwd()\n",
    "xml_list = read_all_xml_files(base_folder)\n",
    "print(\"Number of xml files detected:\",len(xml_list))\n",
    "print(\"XML files list:\")\n",
    "for path in xml_list:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afcb41",
   "metadata": {},
   "source": [
    "Parse xml files to get roi and trajectories. \n",
    "Note that the following steps have to be done manually for every xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb514651",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = xml_list[3] #Enter the position of the xml file from the xml_list. Example here: select the 4th XML file\n",
    "print(xml_path) \n",
    "#Read XML files\n",
    "## Parse the TrackMate XML file\n",
    "def parse_trackmate_with_roi(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    spots = {}\n",
    "    tracks = []\n",
    "\n",
    "    # Find all spots\n",
    "    for spot in root.findall(\".//Spot\"):\n",
    "        spot_id = spot.attrib['ID']\n",
    "        x = float(spot.attrib['POSITION_X'])\n",
    "        y = float(spot.attrib['POSITION_Y'])\n",
    "        t = float(spot.attrib['FRAME'])\n",
    "        radius = float(spot.attrib['RADIUS'])\n",
    "        # Extract ROI points if present\n",
    "        coords_text = spot.text.strip()\n",
    "        coords_array = np.fromstring(coords_text, sep=' ')\n",
    "        coords = coords_array.reshape(-1, 2)\n",
    "        # Shift ROI coordinates by the spot's x and y\n",
    "        coords_shifted = coords + np.array([x, y])\n",
    "        spots[spot_id] = {\"x\": x, \"y\": y, \"t\": t, \"radius\": radius, \"roi_points\": coords_shifted}\n",
    "\n",
    "    # Find all tracks\n",
    "    for track in root.findall(\".//Track\"):\n",
    "        track_id = track.attrib['TRACK_ID']\n",
    "        edges = []\n",
    "        for edge in track.findall(\".//Edge\"):\n",
    "            source_id = edge.attrib['SPOT_SOURCE_ID']\n",
    "            target_id = edge.attrib['SPOT_TARGET_ID']\n",
    "            edges.append((source_id, target_id))\n",
    "        tracks.append({\"track_id\": track_id, \"edges\": edges})\n",
    "\n",
    "    return spots, tracks\n",
    "\n",
    "def get_trajectories_with_roi(spots, tracks):\n",
    "    trajectories = []\n",
    "\n",
    "    for track in tracks:\n",
    "        trajectory = []\n",
    "        for source_id, target_id in track['edges']:\n",
    "            if source_id in spots and target_id in spots:\n",
    "                # print(source_id, target_id)\n",
    "                trajectory.append((spots[source_id], spots[target_id]))\n",
    "        trajectories.append({\"track_id\": track[\"track_id\"], \"trajectory\": trajectory})\n",
    "\n",
    "    return trajectories\n",
    "\n",
    "#Here the xml file is parsed to get the spots and tracks with roi\n",
    "spots, tracks = parse_trackmate_with_roi(xml_path)\n",
    "trajectories = get_trajectories_with_roi(spots, tracks)\n",
    "# print(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b13f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROIs and their centroids at every timepoint in an interactive plot\n",
    "all_times = sorted({spot1['t'] for traj in trajectories for spot1, _ in traj['trajectory']})\n",
    "def plot_rois_at_time(t):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for traj in trajectories:\n",
    "        for spot1, _ in traj['trajectory']:\n",
    "            # print(spot1['t'])\n",
    "            if spot1['t'] == t:\n",
    "                roi_points = spot1['roi_points']\n",
    "                if roi_points.size > 0:\n",
    "                    plt.scatter(roi_points[:, 0], roi_points[:, 1], s=1, c='pink', alpha=0.5)\n",
    "                    # print(max(roi_points[:, 0]), max(roi_points[:, 1]))\n",
    "                plt.scatter(spot1['x'], spot1['y'], s=10, c='blue')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title(f'All ROI Points at Time Point {t}')\n",
    "    plt.axis('equal')\n",
    "    # plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_rois_at_time, t=IntSlider(min=int(min(all_times)), max=int(max(all_times)), step=1, value=int(min(all_times))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the tif file corresponding to the xml file in the current working directory\n",
    "xml_filename = os.path.splitext(os.path.basename(xml_path))[0] #get the xml filename without extension\n",
    "print(xml_filename)\n",
    "tiff_path = None\n",
    "\n",
    "# search inside the same \"rep\" folder as the xml (e.g. rep1, rep2) under the data directory\n",
    "#find which \"rep\" folder the xml file is in\n",
    "rep_name = next((p for p in xml_path.split(os.sep) if p.startswith('rep')), None)\n",
    "# print(rep_name)\n",
    "search_root = os.path.join(base_folder, 'data_mut', rep_name)\n",
    "# print(search_root)\n",
    "\n",
    "# walk the rep folder looking for a tif that contains the xml filename\n",
    "for root_dir, dirs, files in os.walk(search_root):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith(('.tif', '.tiff')) and xml_filename in fname:\n",
    "            tiff_path = os.path.join(root_dir, fname)\n",
    "            break\n",
    "    if tiff_path is not None:\n",
    "        break\n",
    "if tiff_path is None:\n",
    "    raise FileNotFoundError(f\"No .tif file found in {search_root} or {base_folder} containing '{xml_filename}'\")\n",
    "\n",
    "print(\"Selected TIFF:\", tiff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale image_stack frames from 2048x2048 to 682x682 (from pixel size to micron size)\n",
    "with TiffFile(tiff_path) as tif: #open the tif image as an array\n",
    "    image_stack = tif.asarray() \n",
    "#scaling\n",
    "scaled_image_stack = np.array([\n",
    "    resize(frame, (2048*0.3119631, 2048*0.3119631), preserve_range=True, anti_aliasing=True).astype(image_stack.dtype)\n",
    "    for frame in image_stack\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69621ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the ROIs and their centroids from the trajectories on top of the scaled tiff image over time to double check alignment\n",
    "def plot_rois_on_tiff_at_time_scaled(t):\n",
    "    frame_idx = int(t)\n",
    "    img = scaled_image_stack[frame_idx]\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for traj in trajectories:\n",
    "        for spot1, _ in traj['trajectory']:\n",
    "            if spot1['t'] == t:\n",
    "                roi_points = spot1['roi_points']\n",
    "                if roi_points.size > 0:\n",
    "                    plt.plot(roi_points[:, 0], roi_points[:, 1], c='magenta', lw=0.5)\n",
    "                plt.scatter(spot1['x'], spot1['y'], s=1, c='cyan')\n",
    "    plt.title(f\"ROIs on Scaled TIFF Frame {frame_idx}\")\n",
    "    plt.axis('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_rois_on_tiff_at_time_scaled, t=IntSlider(min=int(min(all_times)), max=int(max(all_times)), step=1, value=int(min(all_times))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1c082",
   "metadata": {},
   "source": [
    "Now we detect the vacuole area within the ROIs and track its centroid over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83758e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function for the image stack: Gaussian blur, Otsu thresholding, invert\n",
    "def preprocess_image_stack(image_stack, sigma=1):\n",
    "    # Gaussian blur\n",
    "    blurred = np.array([gaussian_filter(frame, sigma=sigma) for frame in image_stack])\n",
    "    # Otsu thresholding to make binary\n",
    "    binary = np.array([frame > threshold_otsu(frame) for frame in blurred])\n",
    "    # Invert binary image\n",
    "    inverted = np.logical_not(binary)\n",
    "    return inverted.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the vacuole centroids within each ROI using preprocessed images\n",
    "for t in sorted({spot1['t'] for traj in trajectories for spot1, _ in traj['trajectory']}): #loop through all timepoints in the trajectories\n",
    "    t_idx = int(t)\n",
    "    img = scaled_image_stack[t_idx] #scale the image to micron unit\n",
    "    preprocessed = preprocess_image_stack(np.expand_dims(img, 0), sigma=1)[0] #preprocess the single frame\n",
    "    labeled = label(preprocessed)\n",
    "    props = regionprops(labeled) #detect all regions in the preprocessed image (the image is inverted so the vacuole should be labeled)\n",
    "\n",
    "    for traj in trajectories: #loop over each trajectory\n",
    "        track_id = traj['track_id']\n",
    "        for spot1, _ in traj['trajectory']:\n",
    "            if spot1['t'] == t and spot1['roi_points'].size > 0: #loop over each roi at every timepoint\n",
    "                roi = spot1['roi_points']\n",
    "                roi_path = Path(roi)\n",
    "                vacuole_centroids = []\n",
    "                for prop in props:\n",
    "                    y, x = prop.centroid #get the centroid of the detected region\n",
    "                    #detect if the centroid is within the roi\n",
    "                    if roi_path.contains_point((x, y)): \n",
    "                        if hasattr(prop, \"major_axis_length\") and hasattr(prop, \"minor_axis_length\"):\n",
    "                            prop_radius = 0.5 * (prop.major_axis_length + prop.minor_axis_length) / 2\n",
    "                        else:\n",
    "                            prop_radius = np.sqrt(prop.area / np.pi)\n",
    "                        centroid = np.array([x, y])\n",
    "                        roi_radii = np.linalg.norm(roi - centroid, axis=1)\n",
    "                        roi_radius = np.mean(roi_radii)\n",
    "                        if prop_radius < roi_radius * 0.95:\n",
    "                            vacuole_centroids.append((x, y))\n",
    "                if len(vacuole_centroids) > 0:\n",
    "                    spot1['vacuole_centroids'] = vacuole_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186446a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the vacuole centroids detected within each ROI on top of the scaled tiff image over time to double check alignment. \n",
    "# The droplet centroids and vacuole centroids are shown in the same color for each ROI\n",
    "def plot_vacuole_centroids_interactive(t):\n",
    "    frame_idx = int(t)\n",
    "    img = scaled_image_stack[frame_idx]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    # Collect all spots at this time point\n",
    "    spots_at_t = []\n",
    "    for traj in trajectories:\n",
    "        for spot1, _ in traj['trajectory']:\n",
    "            if spot1['t'] == t:\n",
    "                spots_at_t.append(spot1)\n",
    "    n_spots = len(spots_at_t)\n",
    "    colors = cm.get_cmap('tab20', n_spots)\n",
    "\n",
    "    for idx, spot1 in enumerate(spots_at_t):\n",
    "        color = colors(idx)\n",
    "        # Plot spot centroid\n",
    "        plt.scatter(spot1['x'], spot1['y'], s=25, color=color, label='Spot Centroid' if idx == 0 else \"\")\n",
    "        # Plot vacuole centroids in the same color, smaller\n",
    "        if 'vacuole_centroids' in spot1 and spot1['vacuole_centroids']:\n",
    "            vac = np.array(spot1['vacuole_centroids'])\n",
    "            plt.scatter(vac[:, 0], vac[:, 1], s=3, color=color, marker='o', label='Vacuole Centroid' if idx == 0 else \"\")\n",
    "\n",
    "    plt.title(f\"Vacuole Centroids at Frame {frame_idx}\")\n",
    "    plt.axis('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()\n",
    "\n",
    "all_times_sorted = sorted({spot1['t'] for traj in trajectories for spot1, _ in traj['trajectory']})\n",
    "\n",
    "interact(\n",
    "    plot_vacuole_centroids_interactive,\n",
    "    t=IntSlider(min=int(min(all_times_sorted)), max=int(max(all_times_sorted)), step=1, value=int(min(all_times_sorted)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the vacuole centroids and roi centroids (x, y) and the time from the trajectories into a dataframe\n",
    "def extract_vacuole_data(trajectories):\n",
    "    data = []\n",
    "    for traj in trajectories:\n",
    "        track_id = traj['track_id']\n",
    "        for spot1, _ in traj['trajectory']:\n",
    "            if 'vacuole_centroids' in spot1 and spot1['vacuole_centroids']:\n",
    "                for vac_centroid in spot1['vacuole_centroids']:\n",
    "                    data.append({\n",
    "                        'track_id': track_id,\n",
    "                        'time': spot1['t'],\n",
    "                        'roi_x': spot1['x'],\n",
    "                        'roi_y': spot1['y'],\n",
    "                        'vacuole_x': vac_centroid[0],\n",
    "                        'vacuole_y': vac_centroid[1]\n",
    "                    })\n",
    "    return pd.DataFrame(data)\n",
    "data = extract_vacuole_data(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc97272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data by time and track_id, and calculate the mean of the vacuole centroids\n",
    "grouped_data = data.groupby(['track_id', 'time']).agg({\n",
    "    'roi_x': 'mean',\n",
    "    'roi_y': 'mean',\n",
    "    'vacuole_x': 'mean',\n",
    "    'vacuole_y': 'mean'\n",
    "}).reset_index()\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a59f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check by plotting the mean vacuole centroids and roi centroids for each track_id at each time point on the scaled tiff image\n",
    "def plot_mean_vacuole_centroids(t):\n",
    "    frame_idx = int(t)\n",
    "    img = scaled_image_stack[frame_idx]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    # Filter data for the current time point\n",
    "    current_data = grouped_data[grouped_data['time'] == t]\n",
    "\n",
    "    for _, row in current_data.iterrows():\n",
    "        plt.scatter(row['roi_x'], row['roi_y'], s=20, color='blue')\n",
    "        plt.scatter(row['vacuole_x'], row['vacuole_y'], s=10, color='red')\n",
    "\n",
    "    plt.title(f\"Mean Vacuole Centroids at Frame {frame_idx}\")\n",
    "    plt.axis('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_mean_vacuole_centroids,\n",
    "    t=IntSlider(min=int(min(all_times_sorted)), max=int(max(all_times_sorted)), step=1, value=int(min(all_times_sorted)))\n",
    ")\n",
    "#red is vacuole centroids and blue is roi centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc3d2c",
   "metadata": {},
   "source": [
    "Now analysis of the movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d6833",
   "metadata": {},
   "source": [
    "Calculations of vectors v and x to determine angle alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate: the vector between the vacuole centroid and roi centroid for each track_id at each time and add it to the dataframe (vector v)\n",
    "def calculate_vectors(data):\n",
    "    data['vector_x'] = data['vacuole_x'] - data['roi_x']\n",
    "    data['vector_y'] = data['vacuole_y'] - data['roi_y']\n",
    "    return data\n",
    "new_data = calculate_vectors(grouped_data)\n",
    "# print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate vector v and x\n",
    "def calculate_delta_vectors(data):\n",
    "    #sort by track_id and time\n",
    "    data = data.sort_values(by=['track_id', 'time'])\n",
    "    # print(data)\n",
    "    #calculate vector v = vector v1 (t1) - vector v1 (t0)\n",
    "    data['delta_vector_x'] = data.groupby('track_id')['vector_x'].diff().fillna(0)\n",
    "    data['delta_vector_y'] = data.groupby('track_id')['vector_y'].diff().fillna(0)\n",
    "    #calculate vector x = roi (t1) - roi (t0)\n",
    "    data['delta_roi_x'] = data.groupby('track_id')['roi_x'].diff().fillna(0)\n",
    "    data['delta_roi_y'] = data.groupby('track_id')['roi_y'].diff().fillna(0)\n",
    "    #calculate delta time = t1 - t0\n",
    "    data['delta_time'] = data.groupby('track_id')['time'].diff().fillna(0)\n",
    "    return data\n",
    "delta_data = calculate_delta_vectors(new_data)\n",
    "# print(delta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the cosine of the angle between vector v and vector x for each track_id at each time point and add it to the dataframe (calculate through the scalar product)\n",
    "def calculate_cosine_angles(data):\n",
    "    # Calculate length of delta_roi vectors\n",
    "    data['delta_roi_length'] = (data['delta_roi_x']**2 + data['delta_roi_y']**2)**0.5\n",
    "    # Calculate length of delta_vector\n",
    "    data['delta_vector_length'] = (data['delta_vector_x']**2 + data['delta_vector_y']**2)**0.5\n",
    "    # Calculate cosine of the angle between delta_vector and delta_roi\n",
    "    data['cos_angle'] = (\n",
    "        data['delta_vector_x'] * data['delta_roi_x'] +\n",
    "        data['delta_vector_y'] * data['delta_roi_y']\n",
    "    ) / (\n",
    "        data['delta_vector_length'] * data['delta_roi_length']\n",
    "    )\n",
    "    return data\n",
    "\n",
    "delta_data = calculate_cosine_angles(delta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the delta_data dataframe to a csv file using the name of the xml file\n",
    "import os\n",
    "import pandas as pd \n",
    "xml_filename = os.path.basename(xml_path).replace('.xml', '')\n",
    "rep = [part for part in xml_path.split(os.sep) if part.startswith('rep')][0]\n",
    "delta_data.to_csv(f\"{rep}_{xml_filename}_delta.csv\", index=False)\n",
    "print(rep, xml_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
